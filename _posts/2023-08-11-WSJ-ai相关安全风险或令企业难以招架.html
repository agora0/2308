---
layout: post
title: AI相关安全风险或令企业难以招架
date: 2023-08-11 13:33:04.000000000 +08:00
link: https://cn.wsj.com/amp/articles/ai%E7%9B%B8%E5%85%B3%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9%E6%88%96%E4%BB%A4%E4%BC%81%E4%B8%9A%E9%9A%BE%E4%BB%A5%E6%8B%9B%E6%9E%B6-b0cad39b
categories: wsj
---

<main id="main" role="main">
<div>


</div>
<div itemprop="articleLead" data-sbId="CN-TEC-20230811124208">
    <div>
      <div class="media-object scope-
          header
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-228438?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-228438?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-228438?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-228438?width=860&amp;size=1.5005861664712778 860w, https://images.wsj.net/im-228438?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1290w, https://images.wsj.net/im-228438?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=2 1720w, https://images.wsj.net/im-228438?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=3 2580w"
          src="https://images.wsj.net/im-228438?width=860&amp;height=573"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>生成式人工智能使技术供应商和公司更难在确定其代码中的内容的同时保持其数字供应链处于最新状态。</p>
    <p> 图片来源：philippe huguen/Agence France-Presse/Getty Images</p>
  </figcaption>
</figure>

      </div>
    </div>
</div>
<div data-sbId="CN-TEC-20230811124208">

<div>

  <div>
      <p> </p>
              <p><span itemprop="name">
                <a href="https://www.wsj.com/news/author/belle-lin" itemprop="url" rel="author">Belle Lin</a>
              </span></p>

  </div>
    <time>
      2023年8月11日13:00 CST 更新
    </time>
</div>

<div subscriptions-actions subscriptions-display="NOT data.noSharing">
  <div>
    <social-share type="system" width="72" height="24"
      data-param-url="https://cn.wsj.com/articles/ai相关安全风险或令企业难以招架-b0cad39b">
    </social-share>
  </div>
</div>


<div subscriptions-section="content">
</div>
<div subscriptions-section="content-not-granted">
</div>



<section subscriptions-section="content">
      <p>基于生成式人工智能(AI)的工具将极大地提高员工的生产率，但企业里负责落实这些AI工具应用的技术管理者却在忙不迭地了解AI技术的潜在网络安全风险。</p>
      <p>随着像微软(Microsoft, MSFT) Copilot这样的AI工具得到越来越广泛的应用，企业领导者现在有责任了解他们所获得的新功能里面到底包含了什么，以及这些AI应用是否通过了安全审查。Copilot是一种嵌入微软工作场所软件中的生成式AI工具。</p>
      <p>为了加强供应链管理，很多公司长期以来一直依赖于从制造商那里获得的货物清单，其中详细列出了每个组件的来源。最近，软件供应商也面临着设计出类似的“软件物料清单”的挑战，这样的清单要列出软件代码中的内容，包括开源和专有组件。</p>
      <p>制作此类详尽清单的初衷在于，公司由此可以更好地跟踪它们所用软件的细节（比如是否存在Log4j软件缺陷这样的安全漏洞），并且更快地对软件问题作出反应。</p>
      <div> <p>网络监控公司SolarWinds的软件被植入恶意代码的事件迫使许多公司重新评估与第三方软件供应商的关系。SolarWinds的被污染软件导致了众多企业和美国政府2020年遭遇的<a href="https://cn.wsj.com/articles/CN-BGH-20201214081453" target="_blank" >一场大规模黑客攻击</a>。</p>
      <p>咨询公司埃森哲(Accenture)网络韧性服务董事总经理Robert Boyce称，如今，随着AI模型使用公司数据进行训练，企业需要更加警惕这些数据在供应链中可能暴露之处。</p>
      <p>生成式AI面临的挑战是，这项技术发展如此之快，以至于企业急于弄清楚它是否会带来新的网络安全挑战或放大现有的安全弱点。与此同时，技术供应商向企业提供了大量基于生成式AI的新功能和产品，但并非所有这些功能和产品都是企业所需要的，甚至不是企业已经付费购买的。</p>
      <p>分析师表示 ，这造成了管理AI物料清单的难度要大得多。他们补充说，大语言模型非常复杂，几乎不可能对其进行深入审核。</p>
      <p>Forrester Research的网络安全分析师Jeff Pollard称：“大多数安全领导者担心的是，其中一些功能缺乏能见度，无法进行监控，或不具有可解释性。”</p>
      <p>欧盟执法机构欧洲刑警组织(Europol)的数据科学家David Johnson最近在布鲁塞尔的一次会议上表示，在某些情况下，生成式AI可能会带来安全风险，因为模型是用预先存在的代码进行训练。他表示，这些代码可能包含漏洞，因此，如果该模型随后生成新代码，就会继承同样的漏洞。</p>
      <div class="media-object scope-
          wrap
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-833486?width=300&amp;size=1 300w, https://images.wsj.net/im-833486?width=639&amp;size=1 639w, https://images.wsj.net/im-833486?width=639&amp;size=1&amp;pixel_ratio=1.5 958w, https://images.wsj.net/im-833486?width=639&amp;size=1&amp;pixel_ratio=2 1278w, https://images.wsj.net/im-833486?width=639&amp;size=1&amp;pixel_ratio=3 1917w"
          src="https://images.wsj.net/im-833486?width=639&amp;height=639"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>初创公司Protect AI的联合创始人兼总裁Daryan &amp;amp;quot;D&amp;amp;quot; Dehghanpisheh。</p>
    <p> 图片来源：PROTECT AI</p>
  </figcaption>
</figure>

      </div>
      <p>人们对生成式AI的兴趣为Protect AI这样的初创企业创造了机会，该公司旨在通过一个其称之为“机器学习物料清单”的平台，帮助企业追踪各自自主研发的AI系统的组件。Protect AI表示，该公司平台还能识别违反安全策略的行为和恶意代码注入攻击。</p>
      <p>Protect AI总部位于西雅图，联合创始人兼总裁Daryan "D" Dehghanpisheh表示，该公司近期在热门开源机器学习工具MLflow中发现了一个漏洞，攻击者可以利用这个漏洞控制公司的云账户凭据并访问训练数据。</p>
      <p>Dehghanpisheh表示，这些类型攻击与“提示注入”等新攻击形式都是首席信息官需要考虑的基于AI的供应链所涉及的风险。“提示注入”攻击指黑客使用“提示”或基于文本的指令来操纵生成式AI系统以共享敏感信息。</p>
      <p>Protect AI的联合创始人兼首席执行官Ian Swanson说，虽然生成式AI的快速发展已催生大量新工具和AI模型，但多数公司仍在试图把握自己的数据、代码和AI运营的全貌。</p>
      <p>与此同时，一些科技公司领导人，比如总部位于旧金山的销售和营销软件公司6sense的首席信息官Bryan Wise，在签约新生成式AI功能之前，已经侧重于向供应商提出一些更尖锐的问题。</p>
      <p>“如果有人提出关于生成式AI产品的请求，”Wise称，“我们就得越发打起点儿精神来，跟对方说，‘告诉我这些数据会如何被使用？你如何能确保我们的数据不会被用来改进你的模型？’”</p>
      <div class="media-object scope-
          wrap
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-833549?width=300&amp;size=1 300w, https://images.wsj.net/im-833549?width=639&amp;size=1 639w, https://images.wsj.net/im-833549?width=639&amp;size=1&amp;pixel_ratio=1.5 958w, https://images.wsj.net/im-833549?width=639&amp;size=1&amp;pixel_ratio=2 1278w, https://images.wsj.net/im-833549?width=639&amp;size=1&amp;pixel_ratio=3 1917w"
          src="https://images.wsj.net/im-833549?width=639&amp;height=639"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>销售和营销软件公司6sense的首席信息官Bryan Wise。</p>
    <p> 图片来源：6SENSE</p>
  </figcaption>
</figure>

      </div>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-833549?width=540&amp;size=1 540w, https://images.wsj.net/im-833549?width=620&amp;size=1 620w, https://images.wsj.net/im-833549?width=639&amp;size=1 639w, https://images.wsj.net/im-833549?width=700&amp;size=1 700w, https://images.wsj.net/im-833549?width=700&amp;size=1&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-833549?width=700&amp;size=1&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-833549?width=700&amp;size=1&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-833549?width=700&amp;height=700"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>Bryan Wise, CIO of sales and marketing software firm 6sense.</p>
    <p> 图片来源：6sense</p>
  </figcaption>
</figure>

      </div>
      <p>据分析师表示，多数首席信息官都已优先考虑防止公司数据泄露到自身领域之外，或者变成第三方AI模型的训练数据。总部位于休斯顿的殡葬和墓地服务公司Carriage Services的首席信息官Rob Franch称，对于像他这样的一些人士来说，来自微软等成熟供应商的保证和防护措施有助于减轻此类担忧。</p>
      <p>不过，在<a href="https://cn.wsj.com/articles/CN-TEC-20230222162103" target="_blank" >生成式AI助手帮助程序员编写的代码</a>中，存在一个不同但相关的网络安全问题。亚马逊(Amazon.com, AMZN)旗下CodeWhisperer以及微软旗下GitHub Copilot等工具会向开发者推荐新的代码片段，并提供技术建议。</p>
      <p>Forrester的Pollard表示，通过使用这类AI工具，工程师有可能编写出不准确的代码文档，也就是不遵循安全开发流程的代码，或者透露企业通常不会分享的系统信息。</p>
      <p>发动机和发电机制造商康明斯公司(Cummins, CMI)的首席信息安全官Diego Souza说，在解释自身产品的工作原理时，许多软件供应商不愿透露产品中的代码是由AI编写的。Souza表示，在康明斯将新软件纳入公司系统之前，他的安全团队必须对这些AI软件进行测试，确保供应商能提供有关潜在安全漏洞的报告，并提供生命周期更新，这一点至关重要。Souza说：“最大的挑战是要了解代码是否是AI编写的。”</p>
      <p>像漏洞赏金平台HackerOne首席执行官Marten Mickos这样的行业高管对“AI所编写代码的蔓延”感到担忧，Mickos将此称为“嘈杂、平庸、怪异、难以追踪”的代码的扩散，当这些代码编写成软件时，就会成为一个网络安全问题。网络安全公司Snyk的首席执行官Peter McKay说，在开发人员通过使用AI工具更快地构建软件的同时，他们编写出易受攻击的代码的速度也在加快。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-729293?width=540&amp;size=1.6 540w, https://images.wsj.net/im-729293?width=620&amp;size=1.6 620w, https://images.wsj.net/im-729293?width=639&amp;size=1.6 639w, https://images.wsj.net/im-729293?width=700&amp;size=1.6 700w, https://images.wsj.net/im-729293?width=700&amp;size=1.6&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-729293?width=700&amp;size=1.6&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-729293?width=700&amp;size=1.6&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-729293?width=700&amp;height=438"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>微软的GitHub Copilot程序采用ChatGPT创造者OpenAI的生成式人工智能技术，为开发人员推荐新的代码片段并提供技术建议。</p>
    <p> 图片来源：GitHub Inc.</p>
  </figcaption>
</figure>

      </div>
      <p>Pollard表示，虽然围绕软件开发和供应链的网络安全实践已经存在，但使用AI帮助编写代码却加剧了这些挑战。现在，各供应商和公司更难以确定它们代码中的内容，也更难使软件物料清单保持最新。</p>
      <p>二手车零售商CarMax的首席信息和技术官Shamim Mohammad正在利用AI提高效率，改善客户和员工体验。但他表示，使用生成式AI也增加了恶意代码、版权、知识产权和隐私方面的风险。</p>
      <p>他说，CarMax正在开发一种“治理模式”来指导AI的使用，可以通过培训、制定指导方针和界限来降低这些风险。</p>
      <p>6sense的Wise正对生成式AI押下一系列“小赌注”，而不是一头扎进，他说，他的评估过程包括检查该技术的架构和数据实践，而不仅仅是其承诺的业务成果。</p>
      <p>“所有首席信息官都需要研究得更深入一些，”Wise说。“你需要提出正确的问题，才能对自己的决定感到放心。”</p>
      </div>
</section>

</div>
      </main>
